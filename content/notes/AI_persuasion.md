---
title: "AI Persuasion"
date: 2025-12-13
---

I recently took part in a tabletop game at an Effective Altruism conference, where we were essentially playing out the scenario described in [AI 2027](https://ai-2027.com/). One of my big takeaways was just how, as soon as someone gets and deploys AI that is incredibly persuasive, they are nearly unstoppable. As a force for manipulating or disempowering the populace, it could be insanely powerful. As a precise tool to sway leaders to your way of thinking, it could be an easy winning strategy.

## Relevant reading

[Anthropic study: Measuring the Persuasiveness of Language Models](https://www.anthropic.com/research/measuring-model-persuasiveness)

## Takeaways so far

- Claude Opus 3 was already as persuasive as the average human, though maybe not as good as the best humans. Frontier models today could probably do a lot better.
- Using straight up conversations to persuade people might not actually be very effective. Sneakier options would probably work better.

## Potential AI Persuasion Strategies

- Rather than just arguing the actual facts, AIs could generate more supporting material, which may or may not be true. It could write legitimate or just legitimate-looking studies or news articles. People may not be able to fact-check to a sufficient degree.
- Targeting influential individuals may be a powerful strategy for actors hoping to persuade many people.
- Humans could collaborate with AI to make especially persuasive arguments
- AIs could manipulate what content people see, simply allowing people to see more supporting material than contradictory material.
- Persuasion might not just be in written arguments. It could take the form of powerful images, news articles, celebrity statements.
- AI bots could act as if certain arguments were persuasive, so that any observers feel a group pressure effect.

## Mitigation strategies

- Have human-only spaces online and protect these, to allow people to be persuaded in all of the usual ways without unknowingly coming up against super-persuasive AIs disguised as humans.
- Create regulation around algorithms which control what content people see. Robust control here may close off one of the biggest avenues for mass persuasion.
- Deploy AI in fact checking articles, images and other media/information doing the rounds on social media. Flag it so that people can apply the appropriate level of scepticism (wish we could do this in general, but it hasn't worked well).